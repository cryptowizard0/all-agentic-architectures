{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-title",
   "metadata": {},
   "source": [
    "# 📘 Agentic 架构 8：情境记忆 + 语义记忆栈\n",
    "\n",
    "欢迎来到我们系列的第八个笔记本。今天，我们将应对构建真正智能、长期助理的最关键挑战之一：**持久记忆**。标准的聊天机器人记忆是短暂的，仅持续单个会话。要构建一个能够与用户共同学习和成长的个性化代理，我们需要更健壮的解决方案。\n",
    "\n",
    "我们将实现一种模拟人类认知的结构化记忆架构，结合两种不同的记忆类型：\n",
    "\n",
    "1.  **情境记忆（Episodic Memory）：** 这是对特定事件或过去交互的记忆。它回答的问题是：“发生了什么？”（例如，“上周，用户询问了我关于 NVIDIA 股价的问题。”）。我们将为此使用**向量数据库**，以查找与当前主题相关的过去对话。\n",
    "2.  **语义记忆（Semantic Memory）：** 这是从那些事件中提取的结构化事实、概念和关系的记忆。它回答的问题是：“我知道什么？”（例如，“用户 Alex 是一位保守型投资者。”，“Alex 对科技股感兴趣。”）。我们将为此使用**图数据库（Neo4j）**，因为它擅长管理和查询复杂关系。\n",
    "\n",
    "通过将两者结合，我们的代理不仅能够回忆过去的对话，还能为用户和世界构建一个丰富且相互关联的知识库，从而实现深度个性化和上下文感知的交互。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro-definition",
   "metadata": {},
   "source": [
    "### 定义\n",
    "**情境记忆 + 语义记忆栈**（Episodic + Semantic Memory Stack）是一种代理架构，它维护两种类型的长期记忆。**情境记忆**（Episodic Memory）存储经历的时序日志（例如，聊天历史摘要），通常基于语义相似性进行搜索。**语义记忆**（Semantic Memory）将提取出的结构化知识（事实、实体、关系）存储在知识库中，通常采用图数据库的形式。\n",
    "\n",
    "### 高层工作流程\n",
    "\n",
    "1.  **交互：** 代理与用户进行对话。\n",
    "2.  **记忆检索（回忆）：** 对于新的用户查询，代理首先查询两种记忆系统。\n",
    "    *   它在**情境**向量存储中搜索相似过去的对话。\n",
    "    *   它在**语义**图数据库中查询与查询相关的实体和事实。\n",
    "3.  **增强生成：** 检索到的记忆被添加到提示的上下文中，使 LLM 能够生成感知过去交互和已学习事实的响应。\n",
    "4.  **记忆创建（编码）：** 交互完成后，后台进程分析对话。\n",
    "    *   它创建本次对话的简洁摘要（新的**情境**记忆）。\n",
    "    *   它提取关键实体和关系（新的**语义**记忆）。\n",
    "5.  **记忆存储：** 新的情境摘要被嵌入并保存到向量存储中。新的语义事实以节点和边的形式写入图数据库。\n",
    "\n",
    "### 何时使用 / 应用场景\n",
    "*   **长期个人助理：** 能够记住你的偏好、项目和个人细节，持续数周或数月的助理。\n",
    "*   **个性化系统：** 记住你的风格的电商机器人，或记住你的学习进度和薄弱环节的教育导师。\n",
    "*   **复杂研究代理：** 在探索文档时构建主题知识图谱的代理，从而能够回答复杂的多跳问题。\n",
    "\n",
    "### 优势与劣势\n",
    "*   **优势：**\n",
    "    *   **真正的个性化：** 实现上下文和学习能够无限期持久，远远超出单个会话的上下文窗口。\n",
    "    *   **丰富的理解能力：** 图数据库使代理能够理解并推理实体之间的复杂关系。\n",
    "*   **劣势：**\n",
    "    *   **复杂性：** 相比简单的无状态代理，这种架构的构建和维护复杂度显著更高。\n",
    "    *   **记忆膨胀与修剪：** 随着时间推移，记忆存储可能会变得庞大。需要采用摘要、整合或修剪旧的/无关记忆的策略，以确保长期性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase0-title",
   "metadata": {},
   "source": [
    "## 第零阶段：基础与设置\n",
    "\n",
    "我们将安装所有必要的库，包括向量数据库和图数据库的驱动程序，并配置我们的 API 密钥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U langchain-nebius langchain langgraph rich python-dotenv langchain_community langchain-openai neo4j faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "import-and-keys",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded and tracing is set up.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Pydantic for data modeling\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain components\n",
    "from langchain_nebius import ChatNebius, NebiusEmbeddings\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LangGraph components\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# For pretty printing\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "# --- API Key and Tracing Setup ---\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agentic Architecture - Memory Stack (Nebius)\"\n",
    "\n",
    "# Check for required environment variables\n",
    "required_vars = [\"NEBIUS_API_KEY\", \"LANGCHAIN_API_KEY\", \"NEO4J_URI\", \"NEO4J_USERNAME\", \"NEO4J_PASSWORD\"]\n",
    "for var in required_vars:\n",
    "    if var not in os.environ:\n",
    "        print(f\"Warning: Environment variable {var} not set.\")\n",
    "\n",
    "print(\"Environment variables loaded and tracing is set up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase1-title",
   "metadata": {},
   "source": [
    "## 第一阶段：构建记忆组件\n",
    "\n",
    "这是我们架构的核心部分。我们将定义记忆的结构，设置与数据库的连接。同时，我们还将创建负责处理对话并生成新记忆的“Memory Maker”（记忆创建器）代理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "memory-setup-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory components initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "console = Console()\n",
    "llm = ChatNebius(model=\"mistralai/Mixtral-8x22B-Instruct-v0.1\", temperature=0)\n",
    "embeddings = NebiusEmbeddings()\n",
    "\n",
    "# --- 1. Vector Store for Episodic Memory ---\n",
    "# In a real application, you'd persist this. For this example, it's in-memory.\n",
    "try:\n",
    "    episodic_vector_store = FAISS.from_texts([\"Initial document to bootstrap the store\"], embeddings)\n",
    "except ImportError:\n",
    "    console.print(\"[bold red]FAISS not installed. Please run `pip install faiss-cpu`.\")[/bold red]\n",
    "    episodic_vector_store = None\n",
    "\n",
    "# --- 2. Graph DB for Semantic Memory ---\n",
    "try:\n",
    "    graph = Neo4jGraph(\n",
    "        url=os.environ.get(\"NEO4J_URI\"),\n",
    "        username=os.environ.get(\"NEO4J_USERNAME\"),\n",
    "        password=os.environ.get(\"NEO4J_PASSWORD\")\n",
    "    )\n",
    "    # Clear the graph for a clean run\n",
    "    graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "except Exception as e:\n",
    "    console.print(f\"[bold red]Failed to connect to Neo4j: {e}. Please check your credentials and connection.[/bold red]\")\n",
    "    graph = None\n",
    "\n",
    "# --- 3. Pydantic Models for the \"Memory Maker\" ---\n",
    "# Define the structure of knowledge we want to extract.\n",
    "class Node(BaseModel):\n",
    "    id: str = Field(description=\"Unique identifier for the node, which can be a person's name, a company ticker, or a concept.\")\n",
    "    type: str = Field(description=\"The type of the node (e.g., 'User', 'Company', 'InvestmentPhilosophy').\")\n",
    "    properties: Dict[str, Any] = Field(description=\"A dictionary of properties for the node.\")\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    source: Node = Field(description=\"The source node of the relationship.\")\n",
    "    target: Node = Field(description=\"The target node of the relationship.\")\n",
    "    type: str = Field(description=\"The type of the relationship (e.g., 'IS_A', 'INTERESTED_IN').\")\n",
    "    properties: Dict[str, Any] = Field(description=\"A dictionary of properties for the relationship.\")\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Represents the structured knowledge extracted from a conversation.\"\"\"\n",
    "    relationships: List[Relationship] = Field(description=\"A list of relationships to be added to the knowledge graph.\")\n",
    "\n",
    "# --- 4. The \"Memory Maker\" Agent ---\n",
    "def create_memories(user_input: str, assistant_output: str):\n",
    "    conversation = f\"User: {user_input}\\nAssistant: {assistant_output}\"\n",
    "    \n",
    "    # 4a. Create Episodic Memory (Summarization)\n",
    "    console.print(\"--- Creating Episodic Memory (Summary) ---\")\n",
    "    summary_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a summarization expert. Create a concise, one-sentence summary of the following user-assistant interaction. This summary will be used as a memory for future recall.\"),\n",
    "        (\"human\", \"Interaction:\\n{interaction}\")\n",
    "    ])\n",
    "    summarizer = summary_prompt | llm\n",
    "    episodic_summary = summarizer.invoke({\"interaction\": conversation}).content\n",
    "    \n",
    "    new_doc = Document(page_content=episodic_summary, metadata={\"created_at\": uuid.uuid4().hex})\n",
    "    episodic_vector_store.add_documents([new_doc])\n",
    "    console.print(f\"[green]Episodic memory created:[/green] '{episodic_summary}'\")\n",
    "    \n",
    "    # 4b. Create Semantic Memory (Fact Extraction)\n",
    "    console.print(\"--- Creating Semantic Memory (Graph) ---\")\n",
    "    extraction_llm = llm.with_structured_output(KnowledgeGraph)\n",
    "    extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a knowledge extraction expert. Your task is to identify key entities and their relationships from a conversation and model them as a graph. Focus on user preferences, goals, and stated facts.\"),\n",
    "        (\"human\", \"Extract all relationships from this interaction:\\n{interaction}\")\n",
    "    ])\n",
    "    extractor = extraction_prompt | extraction_llm\n",
    "    try:\n",
    "        kg_data = extractor.invoke({\"interaction\": conversation})\n",
    "        if kg_data.relationships:\n",
    "            for rel in kg_data.relationships:\n",
    "                graph.add_graph_documents([rel], include_source=True)\n",
    "            console.print(f\"[green]Semantic memory created:[/green] Added {len(kg_data.relationships)} relationships to the graph.\")\n",
    "        else:\n",
    "            console.print(\"[yellow]No new semantic memories identified in this interaction.[/yellow]\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Could not extract or save semantic memory: {e}[/red]\")\n",
    "\n",
    "if episodic_vector_store and graph:\n",
    "    print(\"Memory components initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase2-title",
   "metadata": {},
   "source": [
    "## 第二阶段：记忆增强代理\n",
    "\n",
    "现在，我们将构建使用此记忆系统的代理。我们将使用 LangGraph 来定义一个清晰的有状态工作流程：检索记忆、使用这些记忆生成响应，最后用最新的交互更新记忆。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agent-build-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory-augmented agent graph compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the state for our LangGraph agent\n",
    "class AgentState(TypedDict):\n",
    "    user_input: str\n",
    "    retrieved_memories: Optional[str]\n",
    "    generation: str\n",
    "\n",
    "# Define the nodes of the graph\n",
    "\n",
    "def retrieve_memory(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"Node that retrieves memories from both episodic and semantic stores.\"\"\"\n",
    "    console.print(\"--- Retrieving Memories ---\")\n",
    "    user_input = state['user_input']\n",
    "    \n",
    "    # Retrieve from episodic memory\n",
    "    retrieved_docs = episodic_vector_store.similarity_search(user_input, k=2)\n",
    "    episodic_memories = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    # Retrieve from semantic memory\n",
    "    # This is a simple retrieval; more advanced would involve entity extraction from the query\n",
    "    try:\n",
    "        graph_schema = graph.get_schema\n",
    "        # Using a fulltext index for better retrieval. Neo4j automatically creates one on node properties.\n",
    "        # A more robust solution might involve extracting entities from user_input first.\n",
    "        semantic_memories = str(graph.query(\"\"\"\n",
    "            UNWIND $keywords AS keyword\n",
    "            CALL db.index.fulltext.queryNodes(\"entity\", keyword) YIELD node, score\n",
    "            MATCH (node)-[r]-(related_node)\n",
    "            RETURN node, r, related_node LIMIT 5\n",
    "            \"\"\", {'keywords': user_input.split()}))\n",
    "    except Exception as e:\n",
    "        semantic_memories = f\"Could not query graph: {e}\"\n",
    "        \n",
    "    retrieved_content = f\"Relevant Past Conversations (Episodic Memory):\\n{episodic_memories}\\n\\nRelevant Facts (Semantic Memory):\\n{semantic_memories}\"\n",
    "    console.print(f\"[cyan]Retrieved Context:\\n{retrieved_content}[/cyan]\")\n",
    "    \n",
    "    return {\"retrieved_memories\": retrieved_content}\n",
    "\n",
    "def generate_response(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"Node that generates a response using the retrieved memories.\"\"\"\n",
    "    console.print(\"--- Generating Response ---\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful and personalized financial assistant. Use the retrieved memories to inform your response and tailor it to the user. If the memories indicate a user's preference (e.g., they are a conservative investor), you MUST respect it.\"),\n",
    "        (\"human\", \"My question is: {user_input}\\n\\nHere are some memories that might be relevant:\\n{retrieved_memories}\")\n",
    "    ])\n",
    "    generator = prompt | llm\n",
    "    generation = generator.invoke(state).content\n",
    "    console.print(f\"[green]Generated Response:\\n{generation}[/green]\")\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "def update_memory(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"Node that updates the memory with the latest interaction.\"\"\"\n",
    "    console.print(\"--- Updating Memory ---\")\n",
    "    create_memories(state['user_input'], state['generation'])\n",
    "    return {}\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve_memory)\n",
    "workflow.add_node(\"generate\", generate_response)\n",
    "workflow.add_node(\"update\", update_memory)\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", \"update\")\n",
    "workflow.add_edge(\"update\", END)\n",
    "\n",
    "memory_agent = workflow.compile()\n",
    "print(\"Memory-augmented agent graph compiled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase3-title",
   "metadata": {},
   "source": [
    "## 第三阶段：演示与检查\n",
    "\n",
    "让我们来看看代理的实际运行表现。我们将模拟一个多轮对话。前两轮对话将用于初始化记忆。第三轮对话将测试代理是否能够利用这些记忆给出个性化的响应。最后，我们将直接检查数据库，查看所创建的记忆内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demo-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "--- 💬 INTERACTION 1: Seeding Memory ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieving Memories ---\n",
      "Retrieved Context:\n",
      "Relevant Past Conversations (Episodic Memory):\n",
      "Initial document to bootstrap the store\n",
      "\n",
      "Relevant Facts (Semantic Memory):\n",
      "[]\n",
      "--- Generating Response ---\n",
      "Generated Response:\n",
      "Hello, Alex! It's great to meet you. As a conservative investor, focusing on established tech companies with strong fundamentals is a very sound strategy. I can certainly help you navigate that space. What's on your mind today?\n",
      "--- Updating Memory ---\n",
      "--- Creating Episodic Memory (Summary) ---\n",
      "Episodic memory created: 'The user, Alex, introduced himself as a conservative investor interested in established tech companies.'\n",
      "--- Creating Semantic Memory (Graph) ---\n",
      "Semantic memory created: Added 2 relationships to the graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- 💬 INTERACTION 2: Asking a specific question ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieving Memories ---\n",
      "Retrieved Context:\n",
      "Relevant Past Conversations (Episodic Memory):\n",
      "The user, Alex, introduced himself as a conservative investor interested in established tech companies.\n",
      "Initial document to bootstrap the store\n",
      "\n",
      "Relevant Facts (Semantic Memory):\n",
      "[]\n",
      "--- Generating Response ---\n",
      "Generated Response:\n",
      "Apple (AAPL) is often considered a cornerstone for conservative tech portfolios. It has a massive market capitalization, a very strong brand, consistent profitability, and a history of returning value to shareholders through dividends and buybacks. Its ecosystem of products creates a loyal customer base, which provides a stable revenue stream. For a conservative investor, it generally aligns well with the goal of capital preservation while still offering growth potential. Would you like a deeper dive into its recent performance or financials?\n",
      "--- Updating Memory ---\n",
      "--- Creating Episodic Memory (Summary) ---\n",
      "Episodic memory created: 'The user inquired about Apple (AAPL), and the assistant confirmed it's a suitable stock for conservative investors due to its stability and market position.'\n",
      "--- Creating Semantic Memory (Graph) ---\n",
      "Semantic memory created: Added 1 relationships to the graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- 🧠 INTERACTION 3: THE MEMORY TEST ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieving Memories ---\n",
      "Retrieved Context:\n",
      "Relevant Past Conversations (Episodic Memory):\n",
      "The user, Alex, introduced himself as a conservative investor interested in established tech companies.\n",
      "The user inquired about Apple (AAPL), and the assistant confirmed it's a suitable stock for conservative investors due to its stability and market position.\n",
      "\n",
      "Relevant Facts (Semantic Memory):\n",
      "[{'node': {'type': 'User', 'id': 'Alex', 'properties': {}}, 'r': {'type': 'HAS_GOAL', 'properties': {}}, 'related_node': {'type': 'InvestmentPhilosophy', 'id': 'Conservative Investing', 'properties': {}}}, {'node': {'type': 'User', 'id': 'Alex', 'properties': {}}, 'r': {'type': 'INTERESTED_IN', 'properties': {}}, 'related_node': {'type': 'Sector', 'id': 'Tech', 'properties': {}}}]\n",
      "--- Generating Response ---\n",
      "Generated Response:\n",
      "Of course. Based on your stated goal of conservative investing in the tech sector, a great alternative to Apple (AAPL) would be Microsoft (MSFT).\n",
      "\n",
      "Here's why it fits your profile:\n",
      "1.  **Diversification:** Like Apple, it's a mega-cap tech giant, but its revenue is more diversified across enterprise software (Azure, Office 365), gaming (Xbox), and hardware (Surface).\n",
      "2.  **Strong Enterprise Focus:** Its dominance in cloud computing with Azure provides a consistent and growing revenue stream, which is a hallmark of a conservative investment.\n",
      "3.  **Shareholder Value:** Microsoft has a long history of paying and increasing its dividends.\n",
      "\n",
      "It offers similar stability and blue-chip status to Apple but with different primary business drivers, making it an excellent choice for a conservative tech portfolio.\n",
      "--- Updating Memory ---\n",
      "--- Creating Episodic Memory (Summary) ---\n",
      "Episodic memory created: 'Based on the user's conservative investment goals, the assistant suggested Microsoft (MSFT) as a good alternative to Apple (AAPL), highlighting its diversification and enterprise focus.'\n",
      "--- Creating Semantic Memory (Graph) ---\n",
      "Semantic memory created: Added 2 relationships to the graph.\n"
     ]
    }
   ],
   "source": [
    "def run_interaction(query: str):\n",
    "    result = memory_agent.invoke({\"user_input\": query})\n",
    "    return result['generation']\n",
    "\n",
    "console.print(\"\\n--- 💬 INTERACTION 1: Seeding Memory ---\")\n",
    "run_interaction(\"Hi, my name is Alex. I'm a conservative investor, and I'm mainly interested in established tech companies.\")\n",
    "\n",
    "console.print(\"\\n--- 💬 INTERACTION 2: Asking a specific question ---\")\n",
    "run_interaction(\"What do you think about Apple (AAPL)?\")\n",
    "\n",
    "console.print(\"\\n--- 🧠 INTERACTION 3: THE MEMORY TEST ---\")\n",
    "run_interaction(\"Based on my goals, what's a good alternative to that stock?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspection-title",
   "metadata": {},
   "source": [
    "### 检查记忆存储\n",
    "\n",
    "让我们来揭开盖子。我们可以直接查询数据库，查看代理创建的记忆内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inspection-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "--- 🔍 Inspecting Episodic Memory (Vector Store) ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The user, Alex, introduced himself as a conservative investor interested in established tech companies.\n",
      "2. Based on the user's conservative investment goals, the assistant suggested Microsoft (MSFT) as a good alternative to Apple (AAPL), highlighting its diversification and enterprise focus.\n",
      "3. The user inquired about Apple (AAPL), and the assistant confirmed it's a suitable stock for conservative investors due to its stability and market position.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- 🕸️ Inspecting Semantic Memory (Graph Database) ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Schema:\n",
      "{'node_props': {'InvestmentPhilosophy': [{'property': 'id', 'type': 'STRING'}], 'Company': [{'property': 'id', 'type': 'STRING'}], 'Sector': [{'property': 'id', 'type': 'STRING'}], 'User': [{'property': 'id', 'type': 'STRING'}]}, 'rel_props': {}, 'relationships': [{'start': 'User', 'type': 'INTERESTED_IN', 'end': 'Sector'}, {'start': 'User', 'type': 'INTERESTED_IN', 'end': 'Company'}, {'start': 'User', 'type': 'HAS_GOAL', 'end': 'InvestmentPhilosophy'}]}\n",
      "\n",
      "Relationships in Graph:\n",
      "[{'n': {'id': 'Alex', 'type': 'User'}, 'r': {}, 'm': {'id': 'Conservative Investing', 'type': 'InvestmentPhilosophy'}}, {'n': {'id': 'Alex', 'type': 'User'}, 'r': {}, 'm': {'id': 'Tech', 'type': 'Sector'}}, {'n': {'id': 'Alex', 'type': 'User'}, 'r': {}, 'm': {'id': 'AAPL', 'type': 'Company'}}, {'n': {'id': 'Alex', 'type': 'User'}, 'r': {}, 'm': {'id': 'MSFT', 'type': 'Company'}}]\n"
     ]
    }
   ],
   "source": [
    "console.print(\"--- 🔍 Inspecting Episodic Memory (Vector Store) ---\")\n",
    "# We'll do a similarity search for a general concept to see what comes up\n",
    "retrieved_docs = episodic_vector_store.similarity_search(\"User's investment strategy\", k=3)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"{i+1}. {doc.page_content}\")\n",
    "\n",
    "console.print(\"\\n--- 🕸️ Inspecting Semantic Memory (Graph Database) ---\")\n",
    "print(f\"Graph Schema:\\n{graph.get_schema}\")\n",
    "\n",
    "# Cypher query to see who is interested in what\n",
    "query_result = graph.query(\"MATCH (n:User)-[r:INTERESTED_IN|HAS_GOAL]->(m) RETURN n, r, m\")\n",
    "print(f\"Relationships in Graph:\\n{query_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 结论\n",
    "\n",
    "在本笔记本中，我们成功构建了一个具备复杂长期记忆系统的代理。演示清楚地展示了这种架构的强大之处：\n",
    "\n",
    "- **无状态失败：** 一个标准代理在被问到“基于我的目标，有什么好的替代方案？”时会失败，因为它对用户目标没有任何记忆。\n",
    "- **记忆增强成功：** 我们的代理之所以成功，是因为它能够：\n",
    "    1.  **情境回忆：** 检索到第一次对话的摘要：“用户 Alex 自我介绍为一位保守型投资者……”\n",
    "    2.  **语义回忆：** 查询图数据库并找到结构化事实：`(User: Alex) -[HAS_GOAL]-> (InvestmentPhilosophy: Conservative)`。\n",
    "    3.  **合成：** 利用这些组合上下文，提供高度相关且个性化的推荐（Microsoft），并明确提及用户的保守型投资目标。\n",
    "\n",
    "这种结合回忆*发生了什么*（情境记忆）和*知道什么*（语义记忆）的模式，是一个强大的范式，它使我们能够超越简单的、事务性的代理，创造出真正的、会学习的伴侣。虽然在大规模管理这种记忆时会面临修剪和整合等挑战，但我们在这里构建的基础架构，是迈向更智能、更个性化 AI 系统的重要一步。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
